{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Modulo3_4_TextGenerator.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMAMcHST21RpwsNnAVyoV83",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pkams/coursera_TensorFlowSpecialization/blob/master/Modulo3_4_TextGenerator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHHUiJSkMisV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        },
        "outputId": "5b30cf46-460b-411e-b311-916a71305b2d"
      },
      "source": [
        "!pip install wget"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp36-none-any.whl size=9682 sha256=93020f095cd80bf3fe43695de436d7169c8ab77c9a1a0cfc132724981153137a\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gv86SJp_MsaM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow.keras.utils as ku \n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "er5_yNosN3f5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "outputId": "d5cfddc0-b597-4d4f-c278-3e0639bce6cd"
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/laurencemoroney-blog.appspot.com/sonnets.txt \\\n",
        "    -O /tmp/sonnets.txt"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-06-25 20:58:19--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/sonnets.txt\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.68.128, 172.217.194.128, 74.125.200.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.68.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 93578 (91K) [text/plain]\n",
            "Saving to: ‘/tmp/sonnets.txt’\n",
            "\n",
            "\r/tmp/sonnets.txt      0%[                    ]       0  --.-KB/s               \r/tmp/sonnets.txt    100%[===================>]  91.38K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2020-06-25 20:58:19 (111 MB/s) - ‘/tmp/sonnets.txt’ saved [93578/93578]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qqbf4WgQN6Uy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "975096dd-6651-406f-f521-168863a5347a"
      },
      "source": [
        "data = open('/tmp/sonnets.txt').read()\n",
        "\n",
        "corpus = data.lower().split('\\n')\n",
        "\n",
        "np.shape(corpus)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2159,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpxccvr3N-Vt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0df559f7-0122-41f2-accd-3e1eb301d0ae"
      },
      "source": [
        "# Tokenizador\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(corpus)\n",
        "word_index = tokenizer.word_index\n",
        "total_words = len(word_index) +1\n",
        "print('Total de palavras: ', total_words)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total de palavras:  3211\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ESJWtzjOQ1z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Criando sequencias de inputs usando os tokens\n",
        "input_sequences = []\n",
        "for line in corpus:\n",
        "  # Tokeniza linha a linha e salva na token_list\n",
        "  # o [0] é pra tirar o valor de dentro da lista e salvá-lo\n",
        "  token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "  # Irá iterar sobre uma lista de 1 até tamanho da token_list\n",
        "  for i in range(1, len(token_list)):\n",
        "    n_gram_sequence = token_list[:i+1]\n",
        "    input_sequences.append(n_gram_sequence)\n",
        "\n",
        "# Pad Sequences\n",
        "# Achando maior comprimento dentro da lista\n",
        "max_sequences_len = max([len(x) for x in input_sequences])\n",
        "# Fazendo padding\n",
        "input_sequences = pad_sequences(input_sequences, maxlen=max_sequences_len, padding='pre')\n",
        "\n",
        "# Criando X e y\n",
        "X, y = input_sequences[:,:-1], input_sequences[:, -1]\n",
        "y = ku.to_categorical(y, num_classes=total_words)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTcOpjnNRyoz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Criando modelo\n",
        "model = tf.keras.models.Sequential([\n",
        "        # Dimensão de entrada: total de palavras\n",
        "        # Dimensão de saída: 100\n",
        "        # Tamanho da entrada: X                            \n",
        "        tf.keras.layers.Embedding(total_words, 100, input_length=X.shape[1]),\n",
        "        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(150, return_sequences=True)),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        tf.keras.layers.LSTM(100),\n",
        "        tf.keras.layers.Dense(total_words/2, activation='relu', kernel_regularizer=tf.keras.regularizers.l1(0.01)),\n",
        "        tf.keras.layers.Dense(total_words, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8CZk308TkkU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "977d7ee6-12bd-4622-8a91-21d3d6e9eac4"
      },
      "source": [
        "history = model.fit(predictors, label, epochs=100, verbose=1)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "484/484 [==============================] - 6s 12ms/step - loss: 3.5941 - accuracy: 0.3201\n",
            "Epoch 2/100\n",
            "484/484 [==============================] - 6s 12ms/step - loss: 3.5747 - accuracy: 0.3233\n",
            "Epoch 3/100\n",
            "484/484 [==============================] - 6s 12ms/step - loss: 3.5721 - accuracy: 0.3224\n",
            "Epoch 4/100\n",
            "484/484 [==============================] - 6s 12ms/step - loss: 3.5561 - accuracy: 0.3315\n",
            "Epoch 5/100\n",
            "484/484 [==============================] - 6s 12ms/step - loss: 3.5446 - accuracy: 0.3308\n",
            "Epoch 6/100\n",
            "484/484 [==============================] - 6s 12ms/step - loss: 3.5335 - accuracy: 0.3318\n",
            "Epoch 7/100\n",
            "484/484 [==============================] - 6s 12ms/step - loss: 3.5128 - accuracy: 0.3365\n",
            "Epoch 8/100\n",
            "484/484 [==============================] - 6s 12ms/step - loss: 3.4965 - accuracy: 0.3451\n",
            "Epoch 9/100\n",
            "484/484 [==============================] - 6s 12ms/step - loss: 3.4767 - accuracy: 0.3459\n",
            "Epoch 10/100\n",
            "484/484 [==============================] - 6s 12ms/step - loss: 3.4590 - accuracy: 0.3494\n",
            "Epoch 11/100\n",
            "484/484 [==============================] - 6s 12ms/step - loss: 3.4526 - accuracy: 0.3470\n",
            "Epoch 12/100\n",
            "484/484 [==============================] - 6s 12ms/step - loss: 3.4476 - accuracy: 0.3525\n",
            "Epoch 13/100\n",
            "484/484 [==============================] - 6s 12ms/step - loss: 3.4276 - accuracy: 0.3542\n",
            "Epoch 14/100\n",
            "484/484 [==============================] - 6s 12ms/step - loss: 3.4173 - accuracy: 0.3599\n",
            "Epoch 15/100\n",
            "484/484 [==============================] - 6s 12ms/step - loss: 3.4081 - accuracy: 0.3561\n",
            "Epoch 16/100\n",
            "484/484 [==============================] - 6s 12ms/step - loss: 3.3895 - accuracy: 0.3663\n",
            "Epoch 17/100\n",
            "484/484 [==============================] - 6s 12ms/step - loss: 3.3848 - accuracy: 0.3614\n",
            "Epoch 18/100\n",
            "484/484 [==============================] - 6s 12ms/step - loss: 3.3622 - accuracy: 0.3679\n",
            "Epoch 19/100\n",
            "484/484 [==============================] - 6s 12ms/step - loss: 3.3565 - accuracy: 0.3721\n",
            "Epoch 20/100\n",
            "484/484 [==============================] - 6s 12ms/step - loss: 3.3437 - accuracy: 0.3713\n",
            "Epoch 21/100\n",
            "484/484 [==============================] - 6s 12ms/step - loss: 3.3090 - accuracy: 0.3816\n",
            "Epoch 22/100\n",
            "484/484 [==============================] - 6s 12ms/step - loss: 3.3237 - accuracy: 0.3798\n",
            "Epoch 23/100\n",
            "484/484 [==============================] - 6s 12ms/step - loss: 3.3102 - accuracy: 0.3825\n",
            "Epoch 24/100\n",
            "484/484 [==============================] - 6s 12ms/step - loss: 3.2881 - accuracy: 0.3875\n",
            "Epoch 25/100\n",
            "484/484 [==============================] - 6s 12ms/step - loss: 3.2619 - accuracy: 0.3917\n",
            "Epoch 26/100\n",
            "484/484 [==============================] - 6s 12ms/step - loss: 3.2568 - accuracy: 0.3910\n",
            "Epoch 27/100\n",
            "484/484 [==============================] - 6s 12ms/step - loss: 3.2531 - accuracy: 0.3948\n",
            "Epoch 28/100\n",
            "484/484 [==============================] - 6s 12ms/step - loss: 3.2506 - accuracy: 0.3972\n",
            "Epoch 29/100\n",
            "484/484 [==============================] - 6s 12ms/step - loss: 3.2353 - accuracy: 0.4003\n",
            "Epoch 30/100\n",
            "484/484 [==============================] - 6s 12ms/step - loss: 3.2163 - accuracy: 0.4009\n",
            "Epoch 31/100\n",
            "484/484 [==============================] - 6s 12ms/step - loss: 3.2021 - accuracy: 0.4078\n",
            "Epoch 32/100\n",
            "484/484 [==============================] - 6s 12ms/step - loss: 3.1918 - accuracy: 0.4096\n",
            "Epoch 33/100\n",
            "484/484 [==============================] - 6s 12ms/step - loss: 3.1741 - accuracy: 0.4116\n",
            "Epoch 34/100\n",
            "484/484 [==============================] - 6s 12ms/step - loss: 3.1598 - accuracy: 0.4164\n",
            "Epoch 35/100\n",
            "484/484 [==============================] - 6s 12ms/step - loss: 3.1575 - accuracy: 0.4168\n",
            "Epoch 36/100\n",
            "484/484 [==============================] - 6s 12ms/step - loss: 3.1502 - accuracy: 0.4166\n",
            "Epoch 37/100\n",
            "484/484 [==============================] - 6s 12ms/step - loss: 3.1282 - accuracy: 0.4203\n",
            "Epoch 38/100\n",
            "484/484 [==============================] - 6s 12ms/step - loss: 3.1170 - accuracy: 0.4251\n",
            "Epoch 39/100\n",
            "484/484 [==============================] - 6s 12ms/step - loss: 3.0972 - accuracy: 0.4241\n",
            "Epoch 40/100\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 3.0994 - accuracy: 0.4266\n",
            "Epoch 41/100\n",
            "484/484 [==============================] - 6s 12ms/step - loss: 3.0967 - accuracy: 0.4261\n",
            "Epoch 42/100\n",
            "484/484 [==============================] - 6s 12ms/step - loss: 3.0653 - accuracy: 0.4349\n",
            "Epoch 43/100\n",
            "484/484 [==============================] - 6s 12ms/step - loss: 3.0699 - accuracy: 0.4364\n",
            "Epoch 44/100\n",
            "484/484 [==============================] - 6s 12ms/step - loss: 3.0551 - accuracy: 0.4393\n",
            "Epoch 45/100\n",
            "484/484 [==============================] - 6s 12ms/step - loss: 3.0372 - accuracy: 0.4393\n",
            "Epoch 46/100\n",
            "484/484 [==============================] - 6s 12ms/step - loss: 3.0094 - accuracy: 0.4510\n",
            "Epoch 47/100\n",
            "484/484 [==============================] - 6s 12ms/step - loss: 3.0053 - accuracy: 0.4520\n",
            "Epoch 48/100\n",
            "484/484 [==============================] - 6s 12ms/step - loss: 3.0097 - accuracy: 0.4489\n",
            "Epoch 49/100\n",
            "484/484 [==============================] - 6s 12ms/step - loss: 2.9956 - accuracy: 0.4529\n",
            "Epoch 50/100\n",
            "484/484 [==============================] - 6s 12ms/step - loss: 2.9832 - accuracy: 0.4552\n",
            "Epoch 51/100\n",
            "484/484 [==============================] - 6s 12ms/step - loss: 2.9734 - accuracy: 0.4627\n",
            "Epoch 52/100\n",
            "484/484 [==============================] - 6s 12ms/step - loss: 2.9604 - accuracy: 0.4639\n",
            "Epoch 53/100\n",
            "484/484 [==============================] - 6s 12ms/step - loss: 2.9525 - accuracy: 0.4670\n",
            "Epoch 54/100\n",
            "484/484 [==============================] - 6s 12ms/step - loss: 2.9424 - accuracy: 0.4627\n",
            "Epoch 55/100\n",
            "484/484 [==============================] - 6s 12ms/step - loss: 2.9340 - accuracy: 0.4673\n",
            "Epoch 56/100\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 2.9099 - accuracy: 0.4748\n",
            "Epoch 57/100\n",
            "484/484 [==============================] - 6s 12ms/step - loss: 2.9061 - accuracy: 0.4741\n",
            "Epoch 58/100\n",
            "484/484 [==============================] - 6s 12ms/step - loss: 2.8879 - accuracy: 0.4777\n",
            "Epoch 59/100\n",
            "484/484 [==============================] - 6s 12ms/step - loss: 2.8714 - accuracy: 0.4825\n",
            "Epoch 60/100\n",
            "484/484 [==============================] - 6s 12ms/step - loss: 2.8694 - accuracy: 0.4822\n",
            "Epoch 61/100\n",
            "484/484 [==============================] - 6s 12ms/step - loss: 2.8681 - accuracy: 0.4797\n",
            "Epoch 62/100\n",
            "484/484 [==============================] - 6s 12ms/step - loss: 2.8648 - accuracy: 0.4822\n",
            "Epoch 63/100\n",
            "484/484 [==============================] - 6s 12ms/step - loss: 2.8491 - accuracy: 0.4864\n",
            "Epoch 64/100\n",
            "484/484 [==============================] - 6s 12ms/step - loss: 2.8424 - accuracy: 0.4904\n",
            "Epoch 65/100\n",
            "484/484 [==============================] - 6s 12ms/step - loss: 2.8241 - accuracy: 0.4897\n",
            "Epoch 66/100\n",
            "484/484 [==============================] - 6s 12ms/step - loss: 2.8044 - accuracy: 0.5007\n",
            "Epoch 67/100\n",
            "484/484 [==============================] - 6s 12ms/step - loss: 2.8041 - accuracy: 0.5004\n",
            "Epoch 68/100\n",
            "484/484 [==============================] - 6s 12ms/step - loss: 2.7921 - accuracy: 0.5008\n",
            "Epoch 69/100\n",
            "484/484 [==============================] - 6s 12ms/step - loss: 2.7798 - accuracy: 0.5038\n",
            "Epoch 70/100\n",
            "484/484 [==============================] - 6s 12ms/step - loss: 2.7709 - accuracy: 0.5100\n",
            "Epoch 71/100\n",
            "484/484 [==============================] - 6s 12ms/step - loss: 2.7595 - accuracy: 0.5136\n",
            "Epoch 72/100\n",
            "484/484 [==============================] - 6s 12ms/step - loss: 2.7539 - accuracy: 0.5131\n",
            "Epoch 73/100\n",
            "484/484 [==============================] - 6s 12ms/step - loss: 2.7541 - accuracy: 0.5142\n",
            "Epoch 74/100\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 2.7482 - accuracy: 0.5138\n",
            "Epoch 75/100\n",
            "484/484 [==============================] - 6s 12ms/step - loss: 2.7299 - accuracy: 0.5191\n",
            "Epoch 76/100\n",
            "484/484 [==============================] - 6s 12ms/step - loss: 2.7113 - accuracy: 0.5228\n",
            "Epoch 77/100\n",
            "484/484 [==============================] - 6s 12ms/step - loss: 2.6986 - accuracy: 0.5237\n",
            "Epoch 78/100\n",
            "484/484 [==============================] - 6s 12ms/step - loss: 2.6974 - accuracy: 0.5233\n",
            "Epoch 79/100\n",
            "484/484 [==============================] - 6s 12ms/step - loss: 2.6971 - accuracy: 0.5209\n",
            "Epoch 80/100\n",
            "484/484 [==============================] - 6s 12ms/step - loss: 2.7017 - accuracy: 0.5247\n",
            "Epoch 81/100\n",
            "484/484 [==============================] - 6s 12ms/step - loss: 2.6806 - accuracy: 0.5298\n",
            "Epoch 82/100\n",
            "484/484 [==============================] - 6s 12ms/step - loss: 2.6639 - accuracy: 0.5344\n",
            "Epoch 83/100\n",
            "484/484 [==============================] - 6s 12ms/step - loss: 2.6502 - accuracy: 0.5315\n",
            "Epoch 84/100\n",
            "484/484 [==============================] - 6s 12ms/step - loss: 2.6487 - accuracy: 0.5337\n",
            "Epoch 85/100\n",
            "484/484 [==============================] - 6s 12ms/step - loss: 2.6391 - accuracy: 0.5387\n",
            "Epoch 86/100\n",
            "484/484 [==============================] - 6s 12ms/step - loss: 2.6121 - accuracy: 0.5479\n",
            "Epoch 87/100\n",
            "484/484 [==============================] - 6s 12ms/step - loss: 2.6220 - accuracy: 0.5444\n",
            "Epoch 88/100\n",
            "484/484 [==============================] - 6s 12ms/step - loss: 2.6163 - accuracy: 0.5447\n",
            "Epoch 89/100\n",
            "484/484 [==============================] - 6s 12ms/step - loss: 2.5898 - accuracy: 0.5514\n",
            "Epoch 90/100\n",
            "484/484 [==============================] - 6s 12ms/step - loss: 2.5877 - accuracy: 0.5530\n",
            "Epoch 91/100\n",
            "484/484 [==============================] - 6s 12ms/step - loss: 2.5758 - accuracy: 0.5559\n",
            "Epoch 92/100\n",
            "484/484 [==============================] - 6s 12ms/step - loss: 2.5816 - accuracy: 0.5540\n",
            "Epoch 93/100\n",
            "484/484 [==============================] - 6s 12ms/step - loss: 2.5753 - accuracy: 0.5573\n",
            "Epoch 94/100\n",
            "484/484 [==============================] - 6s 12ms/step - loss: 2.5571 - accuracy: 0.5595\n",
            "Epoch 95/100\n",
            "484/484 [==============================] - 6s 12ms/step - loss: 2.5557 - accuracy: 0.5613\n",
            "Epoch 96/100\n",
            "484/484 [==============================] - 6s 12ms/step - loss: 2.5297 - accuracy: 0.5673\n",
            "Epoch 97/100\n",
            "484/484 [==============================] - 6s 12ms/step - loss: 2.5179 - accuracy: 0.5693\n",
            "Epoch 98/100\n",
            "484/484 [==============================] - 6s 12ms/step - loss: 2.5285 - accuracy: 0.5661\n",
            "Epoch 99/100\n",
            "484/484 [==============================] - 6s 12ms/step - loss: 2.5218 - accuracy: 0.5653\n",
            "Epoch 100/100\n",
            "484/484 [==============================] - 6s 12ms/step - loss: 2.5278 - accuracy: 0.5698\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxt01Y8EVGYI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "0ddb07d2-5d50-4a57-fa3a-0edec1dffa93"
      },
      "source": [
        "# Testando predição de novo texto\n",
        "\n",
        "seed_text = \"Help me Obi Wan Kenobi, you're my only hope\"\n",
        "next_words = 100\n",
        "  \n",
        "for _ in range(next_words):\n",
        "\ttoken_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "\ttoken_list = pad_sequences([token_list], maxlen=max_sequences_len-1, padding='pre')\n",
        "\tpredicted = np.argmax(model.predict(token_list, verbose=0), axis = -1)\n",
        "\toutput_word = \"\"\n",
        "\tfor word, index in tokenizer.word_index.items():\n",
        "\t\tif index == predicted:\n",
        "\t\t\toutput_word = word\n",
        "\t\t\tbreak\n",
        "\tseed_text += \" \" + output_word\n",
        "print(seed_text)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Help me Obi Wan Kenobi, you're my only hope receives light confined memory shalt then thee is i then i in thee forbear to thou joy more ' i in men let joy you control i store her beauty most shalt i say born day that been is in for my liberty virtue hell is action warm less thought the ornament itself more virtue shall thought buried art ever can evermore disabled physic the time day be in at such woe did heinous fell more brow ornament your warm to thou warm in time the style had lawful best matcheth let mine than thee shall know doth reason no\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekl-5uORYj61",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}